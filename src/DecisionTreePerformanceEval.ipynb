{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "liked-building",
   "metadata": {},
   "source": [
    "# Evaluation of Decision Tree Algorithm Performance #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "promising-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-reminder",
   "metadata": {},
   "source": [
    "## Read In Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mounted-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_models = None\n",
    "with open('./clfs.p', 'rb') as models:\n",
    "    fitted_models = pickle.load(models)\n",
    "\n",
    "data = sio.loadmat('../Data/data_cube_subject1.mat')\n",
    "channel_labels = sio.loadmat('../Data/channel_label.mat')\n",
    "data_matrix = data['data_cube']\n",
    "data_labels = data['event_label'].reshape((200,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "selected-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = fitted_models[1]['train_idx']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-register",
   "metadata": {},
   "source": [
    "#### Prepare Data for use in testing ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "mediterranean-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Format(X:np.ndarray, \n",
    "#            y:np.ndarray, \n",
    "#            trials_per_condition:int=100, \n",
    "#            reduction_method:str= 'Ave_over_samples'):\n",
    "#     \"\"\"\n",
    "#     Functionality: Method prepares data for usage in a ML algorithm. After feeding X,y through this algorithm, you can expect:\n",
    "#         X and y will be split according to the different experiment conditions. Location of split is determined by trials_per_condition\n",
    "#         X will have its number of dimensions reduced by one, according to the reducion method specified. Also, output data will be transposed\n",
    "#             so that the first index is the number of trials.\n",
    "#     Param:\n",
    "#         X:: ndarray of unlabeled EEG data with dimensions (channels, samples, trials). \n",
    "#         y:: ndarray of data labels for X with dimensions (trials).\n",
    "#         trials_per_condition:: number of trials done for each condition. Method assumes equal number of trials per condition\n",
    "#         reduction_method:: function with signature (channels x samples x trials)darray ==> ndarray, where the co-domain contains arrays of one fewer dimension than the domain\n",
    "#     Returns:\n",
    "#         X_by_classes_reduced:: Dictionary with keys A,B and values of dimensionality reduced X separated by condition type A or B. The first index of arrays in X_by_classes_reduced\n",
    "#                                     will correspond to the trial number. The second index will correspond to a value which depends on the reduction_method.\n",
    "#         y_by_classes:: Dictionary with keys A,B and values of y separated by condition type A or B.\n",
    "#     \"\"\"\n",
    "#     X_by_classes, y_by_classes = class_split(X,y, trials_per_condition)\n",
    "#     reduce = reduction_methods[reduction_method]\n",
    "#     X_by_classes_reduced = {typ: reduce(X_by_classes[typ]).T\\\n",
    "#                             for typ in X_by_classes}\n",
    "#     return X_by_classes_reduced, y_by_classes\n",
    "\n",
    "# def class_split(X:np.ndarray, y:np.ndarray, trials_per_condition:int):\n",
    "#     \"\"\"\n",
    "#     Helper Method to Format, separates X and y into condition types\n",
    "#     \"\"\"\n",
    "#     AX, BX = X[:,:,:trials_per_condition], X[:,:,trials_per_condition:]\n",
    "#     Ay, By = y[:trials_per_condition], y[trials_per_condition:]\n",
    "#     X_dict, y_dict = {'A': AX, 'B':BX}, {'A':Ay, 'B':By}\n",
    "#     return X_dict, y_dict\n",
    "# #Reduction methods\n",
    "# #All reduction methods should assume a np.ndarray of shape (channels x samples x trials)\n",
    "# #All reduction methods should return a np.ndarray of shape (dim x trials), where dim depends on the reduction method\n",
    "# reduction_methods = {\n",
    "#     'Ave_over_channels': lambda X: np.mean(X,0),\n",
    "#     'Ave_over_samples': lambda X: np.mean(X,1),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "applicable-trustee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': {'X': {'A': array([[-1.32261406e-14, -5.49186600e-15,  4.68384451e-15, ...,\n",
       "            5.31244354e-15,  2.80673315e-15, -1.93071475e-16],\n",
       "          [-6.68553412e-15, -1.38140407e-15,  3.79938855e-15, ...,\n",
       "           -4.28864358e-15, -4.64637177e-15, -9.01256655e-15],\n",
       "          [-8.29165056e-15, -5.40997193e-16, -8.14970084e-16, ...,\n",
       "            4.45603009e-15,  7.73278557e-16, -3.69962668e-15],\n",
       "          ...,\n",
       "          [-2.19332174e-14, -8.97732728e-16,  1.75551108e-15, ...,\n",
       "           -1.06511924e-15, -1.07926458e-15, -4.96377333e-15],\n",
       "          [ 1.46540754e-15, -1.15619538e-15, -1.67014271e-16, ...,\n",
       "           -3.30057921e-16,  1.64929695e-15, -6.84882594e-15],\n",
       "          [ 3.45444079e-16,  1.69744074e-15, -1.11524834e-15, ...,\n",
       "           -3.12686451e-16,  1.27159157e-15, -4.84812898e-15]]),\n",
       "   'B': array([[ 1.68552887e-15,  2.12180092e-17, -1.24603069e-15, ...,\n",
       "            1.14056106e-15, -5.61470711e-18,  3.61425831e-15],\n",
       "          [-9.34585060e-16, -1.37929468e-15,  1.30831982e-15, ...,\n",
       "            5.49434764e-16,  8.21918672e-16,  2.77099755e-15],\n",
       "          [ 9.63272801e-15,  1.57832209e-15,  4.39436138e-16, ...,\n",
       "           -3.74429617e-15,  2.40123341e-15, -7.95365140e-17],\n",
       "          ...,\n",
       "          [-3.70061933e-15, -4.68235552e-15, -1.12170060e-16, ...,\n",
       "            1.95056786e-16, -1.89845345e-15, -2.52730065e-15],\n",
       "          [ 3.84058374e-15, -2.26523962e-15, -4.97816683e-16, ...,\n",
       "           -8.85746414e-15, -5.88049059e-15, -1.47012265e-15],\n",
       "          [ 7.12031719e-15, -2.40967098e-16, -2.22156279e-15, ...,\n",
       "           -2.99384869e-15,  5.76633522e-15,  1.31427575e-15]])},\n",
       "  'y': {'A': array([1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "          0, 0, 0, 1, 0, 0, 1, 1], dtype=uint8),\n",
       "   'B': array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "          0, 0, 0, 0, 1, 0, 1, 1], dtype=uint8)}},\n",
       " 'train': {'X': {'A': array([[-1.86371051e-16,  8.83091061e-16,  1.83765331e-16, ...,\n",
       "           -1.50374885e-15, -2.11435600e-15,  3.83258046e-16],\n",
       "          [ 3.44401791e-15, -5.01787305e-16, -1.13162716e-16, ...,\n",
       "           -4.94937983e-15, -1.70736729e-16, -6.05519794e-17],\n",
       "          [ 4.31805099e-16, -2.13098298e-15, -9.28132800e-16, ...,\n",
       "            1.36787914e-15,  6.35249824e-15, -1.13013817e-15],\n",
       "          ...,\n",
       "          [-1.60822583e-15, -3.29437511e-16, -2.82038216e-15, ...,\n",
       "           -2.29526745e-15, -2.52878963e-16,  9.17958082e-16],\n",
       "          [-4.16418941e-16, -2.00714922e-15, -1.64085938e-15, ...,\n",
       "            3.07226846e-16,  4.81934197e-15, -4.58408264e-15],\n",
       "          [-1.64284469e-16, -2.42207918e-16, -3.26087299e-15, ...,\n",
       "            1.23089270e-16,  1.63788141e-16, -1.17828196e-15]]),\n",
       "   'B': array([[-1.16357825e-15, -3.38644390e-15, -1.76320416e-15, ...,\n",
       "           -3.38991819e-16, -1.23473924e-15,  2.17208512e-15],\n",
       "          [ 5.26107362e-17, -1.19962405e-15, -3.36013853e-16, ...,\n",
       "           -1.84212026e-15,  4.96079536e-15,  3.61475464e-15],\n",
       "          [ 9.32103421e-16, -6.94858780e-17, -1.00655258e-15, ...,\n",
       "            8.03058219e-16, -1.54921247e-14,  3.50655520e-16],\n",
       "          ...,\n",
       "          [-5.06254254e-16, -3.55866961e-16,  6.12964710e-17, ...,\n",
       "            2.70846026e-15, -1.43835768e-15, -5.60850301e-17],\n",
       "          [ 3.18642384e-15, -4.20191031e-15, -5.92540825e-15, ...,\n",
       "            2.77968329e-15, -1.62944384e-15,  6.20409625e-16],\n",
       "          [ 9.72802293e-16,  1.14552433e-15, -4.09470353e-15, ...,\n",
       "           -2.93329671e-15, -1.03037631e-15, -2.16398877e-16]])},\n",
       "  'y': {'A': array([0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "          0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "          0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "          0, 1, 1, 0], dtype=uint8),\n",
       "   'B': array([0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "          0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "          1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "          1, 0, 1, 1], dtype=uint8)}}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def split(X,y, train_idx):\n",
    "#     all_idx = list(range(len(X['A'])))\n",
    "#     test_idx = [idx for idx in all_idx if idx not in train_idx]\n",
    "#     X_train = {'A': X['A'][train_idx], 'B':X['B'][train_idx]}\n",
    "#     y_train = {'A': y['A'][train_idx], 'B':y['B'][train_idx]}\n",
    "#     X_test = {'A': X['A'][test_idx], 'B':X['B'][test_idx]}\n",
    "#     y_test = {'A': y['A'][test_idx], 'B':y['B'][test_idx]}\n",
    "#     test_dict = {'X': X_test, 'y': y_test}\n",
    "#     train_dict = {'X': X_train, 'y': y_train}\n",
    "#     return {'test': test_dict, 'train': train_dict}\n",
    "\n",
    "X_ave_over_samples, y_ave_over_samples = Format(data_matrix, data_labels, reduction_method = 'Ave_over_samples')\n",
    "X_ave_over_channels, y_ave_over_channels = Format(data_matrix, data_labels, reduction_method = 'Ave_over_channels')\n",
    "\n",
    "data_ave_over_samples = split(X_ave_over_samples, y_ave_over_samples, train_idx)\n",
    "data_ave_over_channels = split(X_ave_over_channels, y_ave_over_channels, train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "middle-spectrum",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "assisted-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_test_partition(X_dict, y_dict, test_size=0.3, random_state=None):\n",
    "#     all_idx = list(range(X_dict['A'].shape[0]))\n",
    "#     train_idx, test_idx = train_test_split(all_idx, test_size=test_size, random_state=random_state)\n",
    "#     #make splits\n",
    "#     X_dict_train = {key:X_dict[key][train_idx] for key in X_dict}\n",
    "#     X_dict_test = {key:X_dict[key][test_idx] for key in X_dict}\n",
    "#     y_dict_train = {key:y_dict[key][train_idx] for key in y_dict}\n",
    "#     y_dict_test = {key:y_dict[key][test_idx] for key in y_dict}\n",
    "    \n",
    "#     return (X_dict_train, \n",
    "#             X_dict_test, \n",
    "#             y_dict_train, \n",
    "#             y_dict_test, \n",
    "#             train_idx, \n",
    "#             test_idx)\n",
    "\n",
    "# def recombine_test_train_partitions(X_train_dict, y_train_dict, X_test_dict, y_test_dict):\n",
    "#     XA_train, XB_train = X_train_dict['A'], X_train_dict['B']\n",
    "#     yA_train, yB_train = y_train_dict['A'], y_train_dict['B']\n",
    "#     XA_test, XB_test = X_test_dict['A'], X_test_dict['B']\n",
    "#     yA_test, yB_test = y_test_dict['A'], y_test_dict['B']\n",
    "#     XA = np.vstack([XA_train, XA_test])\n",
    "#     XB = np.vstack([XA_test, XB_test])\n",
    "#     yA = np.hstack([yA_train, yA_test])\n",
    "#     yB = np.hstack([yB_train, yB_test])\n",
    "#     X_dict = {'A': XA, 'B': XB}\n",
    "#     y_dict = {'A': yA, 'B': yB}\n",
    "#     return X_dict, y_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "right-trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function used to re train model only when necessary\n",
    "#function compares training data to training data model was last\n",
    "#trained with. Only retrains if differences between old and new training data \n",
    "#are found\n",
    "last_X_train = np.array([])\n",
    "last_y_train = np.array([])\n",
    "last_clf = None\n",
    "\n",
    "def retrain(clf, X, y):\n",
    "    #exeption prevention\n",
    "    #if no training data is given, return input classifier\n",
    "    if X is None:\n",
    "        return clf['clf']\n",
    "    #all of the conditions in the following list must be true \n",
    "    #for the previous trained model to be used\n",
    "    no_retrain_conditions = [\n",
    "        last_X_train.shape == X.shape,\n",
    "        (last_X_train == X).all(),\n",
    "        (last_y_train == y).all()\n",
    "    ]\n",
    "    \n",
    "    if no_retrain_conditions.all():\n",
    "        return last_clf\n",
    "    else:\n",
    "        clf_type = clf['clf_type']\n",
    "        clf_new = clfs[clf_type]\n",
    "        clf_new.fit(X, y)\n",
    "        last_clf = clf_new\n",
    "        last_X_train = X\n",
    "        last_y_train = y\n",
    "        return clf_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "periodic-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_condition(clf, \n",
    "                   X_test:np.ndarray,\n",
    "                   y_test:np.ndarray,\n",
    "                   X_train:np.ndarray=None,\n",
    "                   y_train:np.ndarray=None,\n",
    "                   n_rounds:int=1,\n",
    "                   n_train_sample_bootstrap:int=None,\n",
    "                   n_test_sample_bootstrap:int=None):\n",
    "    aucs = [] #return variable\n",
    "    X, y = None, None #placeholder variables for features and labels\n",
    "    for n in range(n_rounds):\n",
    "        X,y = bootstrap(X_train, y_train, n_train_sample_bootstrap)\n",
    "        mod = retrain(clf, X, y)\n",
    "        X,y = bootstrap(X_test, y_test, n_test_sample_bootstrap)\n",
    "        y_pred = clf.predict_proba(X)\n",
    "        aucs.append(roc_auc_score(y,y_pred))\n",
    "    return np.array(aucs)\n",
    "        \n",
    "def evaluate_model(clf:dict,\n",
    "                  X_test_dict:dict,\n",
    "                  y_test_dict:dict,\n",
    "                  X_train_dict:dict=None,\n",
    "                  y_train_dict:dict=None,\n",
    "                  n_rounds_bootstrap:int=1,\n",
    "                  n_train_sample_bootstrap:int=None,\n",
    "                  n_test_sample_bootstrap:int=None,\n",
    "                  redo_test_train_partition:bool=False,\n",
    "                  train_AB_separately:bool=False):   \n",
    "    if redo_test_train_partition:\n",
    "        if X_train_dict is not None:\n",
    "            X_dict, y_dict = recombine_test_train_partitions(X_train_dict,\n",
    "                                                             y_train_dict, \n",
    "                                                             X_test_dict, \n",
    "                                                             y_test_dict)\n",
    "        else:\n",
    "            X_dict, y_dict = X_test_dict, y_test_dict\n",
    "        X_train_dict, X_test_dict, y_train_dict, y_test_dict, _, _ = test_train_partition(X_dict, y_dict)\n",
    "\n",
    "    if train_AB_separately:\n",
    "        XA_train, XB_train = X_train_dict['A'], X_train_dict['B']\n",
    "        yA_train, yB_train = y_train_dict['A'], X_train_dict['B']\n",
    "    else:\n",
    "        if X_train_dict is None:\n",
    "            XA_train, XB_train, yA_train, yB_train = None, None, None, None\n",
    "        else:\n",
    "            XA_train = np.vstack([X_train_dict['A'], X_train_dict['B']])\n",
    "            XB_train = XA_train\n",
    "            yA_train = np.hstack([y_train_dict['A'], X_train_dict['B']])\n",
    "            yB_train = yA_train\n",
    "    A_aucs = evaluate_model_on_condition(X_test_dict['A'],\n",
    "                                        y_test_dict['A'],\n",
    "                                        XA_train,\n",
    "                                        yA_train,\n",
    "                                        n_rounds_bootstrap,\n",
    "                                        n_train_sample_bootstrap,\n",
    "                                        n_test_sample_bootstrap)\n",
    "    B_aucs = evaluate_model_on_condition(X_test_dict['B'],\n",
    "                                        y_test_dict['B'],\n",
    "                                        XB_train,\n",
    "                                        yB_train,\n",
    "                                        n_rounds_bootstrap,\n",
    "                                        n_train_sample_bootstrap,\n",
    "                                        n_test_sample_bootstrap)\n",
    "    return {'A_aucs': A_aucs, 'B_aucs': B_aucs}\n",
    "    \n",
    "     \n",
    "\n",
    "def bootstrap(X,y, n_sample_bootstrap):\n",
    "    if None in [X, y, n_sample_bootstrap]:\n",
    "        return X, y\n",
    "    bootstrap_idx = np.random.randint(X.shape[0], size=n_sample_bootstraps)\n",
    "    return X[bootstrap_idx], y[bootstrap_idx]\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "directed-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#The following function calls evaluate_model on the specified \n",
    "# input, and returns an auc distribution in a dictionary along\n",
    "# with information speciyfing which model was tested\n",
    "def get_model_eval(clf:dict,\n",
    "                   X_test_dict:dict,\n",
    "                   y_test_dict:dict,\n",
    "                   X_train_dict:dict=None,\n",
    "                   y_train_dict:dict=None,\n",
    "                   n_rounds_bootstrap:int=1,\n",
    "                   n_train_sample_bootstrap:int=None,\n",
    "                   n_test_sample_bootstrap:int=None,\n",
    "                   n_rounds_test_train_split:int=None,\n",
    "                   separate_AB_models:bool=False):\n",
    "    output_dict = {'clf_type': clf['clf_type'],\n",
    "                   'reduction_method': clf['reduction_method'],\n",
    "                   'n_rounds_test_train_split': n_rounds_test_train_split,\n",
    "                   'separate_AB_models' : separate_AB_models}\n",
    "    if n_rounds_test_train_split is None:\n",
    "        output_dict['aucs'] = evaluate_model(clf, \n",
    "                                             X_test_dict,\n",
    "                                             y_test_dict,\n",
    "                                             X_train_dict,\n",
    "                                             y_train_dict,\n",
    "                                             n_rounds_bootstrap,\n",
    "                                             n_train_sample_bootstrap,\n",
    "                                             n_test_sample_bootstrap,\n",
    "                                             False,\n",
    "                                             separate_AB_models)\n",
    "    else:\n",
    "        auc_dict = {'A': [], 'B': []}\n",
    "        for n in range(n_rounds_test_train_split):\n",
    "            auc_i = evaluate_model(clf, \n",
    "                                   X_test_dict,\n",
    "                                   y_test_dict,\n",
    "                                   X_train_dict,\n",
    "                                   y_train_dict,\n",
    "                                   n_rounds_bootstrap,\n",
    "                                   n_train_sample_bootstrap,\n",
    "                                   n_test_sample_bootstrap,\n",
    "                                   True,\n",
    "                                   separate_AB_models)\n",
    "            auc_dict['A'] += auc_i['A']\n",
    "            auc_dict['B'] += auc_i['B']\n",
    "            \n",
    "        output_dict['aucs'] = auc_dict\n",
    "        \n",
    "    return output_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "indoor-driving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf_type': 'RandomForestClassifier',\n",
       " 'reduction_method': 'Ave_over_samples',\n",
       " 'train_idx': [67,\n",
       "  99,\n",
       "  54,\n",
       "  95,\n",
       "  88,\n",
       "  40,\n",
       "  48,\n",
       "  59,\n",
       "  23,\n",
       "  34,\n",
       "  86,\n",
       "  53,\n",
       "  77,\n",
       "  15,\n",
       "  83,\n",
       "  41,\n",
       "  45,\n",
       "  91,\n",
       "  26,\n",
       "  98,\n",
       "  43,\n",
       "  55,\n",
       "  24,\n",
       "  4,\n",
       "  58,\n",
       "  49,\n",
       "  21,\n",
       "  87,\n",
       "  3,\n",
       "  74,\n",
       "  30,\n",
       "  66,\n",
       "  70,\n",
       "  42,\n",
       "  47,\n",
       "  89,\n",
       "  8,\n",
       "  60,\n",
       "  0,\n",
       "  90,\n",
       "  57,\n",
       "  22,\n",
       "  61,\n",
       "  63,\n",
       "  7,\n",
       "  96,\n",
       "  13,\n",
       "  68,\n",
       "  85,\n",
       "  14,\n",
       "  29,\n",
       "  28,\n",
       "  11,\n",
       "  18,\n",
       "  20,\n",
       "  50,\n",
       "  25,\n",
       "  6,\n",
       "  71,\n",
       "  76,\n",
       "  1,\n",
       "  16,\n",
       "  64,\n",
       "  79,\n",
       "  5,\n",
       "  75,\n",
       "  9,\n",
       "  72,\n",
       "  12,\n",
       "  37],\n",
       " 'test_idx': [80,\n",
       "  84,\n",
       "  33,\n",
       "  81,\n",
       "  93,\n",
       "  17,\n",
       "  36,\n",
       "  82,\n",
       "  69,\n",
       "  65,\n",
       "  92,\n",
       "  39,\n",
       "  56,\n",
       "  52,\n",
       "  51,\n",
       "  32,\n",
       "  31,\n",
       "  44,\n",
       "  78,\n",
       "  10,\n",
       "  2,\n",
       "  73,\n",
       "  97,\n",
       "  62,\n",
       "  19,\n",
       "  35,\n",
       "  94,\n",
       "  27,\n",
       "  46,\n",
       "  38],\n",
       " 'clf': GridSearchCV(estimator=RandomForestClassifier(), n_jobs=7,\n",
       "              param_grid={'criterion': ['gini', 'entropy'],\n",
       "                          'max_depth': (None, 10, 50, 100, 500),\n",
       "                          'max_features': ('auto', 'sqrt', 'log2', None),\n",
       "                          'min_impurity_split': (None, 0.5),\n",
       "                          'min_samples_leaf': [1, 2, 4],\n",
       "                          'min_samples_split': [2, 4, 5],\n",
       "                          'n_estimators': [50, 100, 200, 500],\n",
       "                          'random_state': [1]})}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./clfs.p', 'rb') as models:\n",
    "    fitted_models = pickle.load(models)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
