{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "strange-reminder",
   "metadata": {},
   "source": [
    "# Project Code Draft ##\n",
    "\n",
    "## Import Statements ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "smoking-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import inspect\n",
    "import os\n",
    "import contextlib\n",
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-future",
   "metadata": {},
   "source": [
    "## Data Pre-processing Functions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "incorrect-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function-type alias for use in type hints\n",
    "function = type(lambda x: x)\n",
    "\n",
    "######################## Data Dimensionality Reduction Methods ##############################################################\n",
    "def sliding_window(X:np.ndarray, y:np.ndarray, window_length:int, step_size:int, step:int):\n",
    "    w_start_idx = step_size*step\n",
    "    w_end_idx = min( [X.shape[1]-1, w_start_idx + window_length] )\n",
    "    if y is not None:\n",
    "        return X[:, w_start_idx:w_end_idx, :], y[w_start_idx:w_end_idx]\n",
    "    if y is None:\n",
    "        return X[:, w_start_idx:w_end_idx, :]\n",
    "\n",
    "#################### Laterized Readiness Potential Logic\n",
    "def calc_lrp(X:np.ndarray): \n",
    "    X_reduced = X[23,:,:] - X[7,:,:]\n",
    "    return X_reduced.T\n",
    "\n",
    "def sliding_lrp(X:np.ndarray, y:np.ndarray, window_length:int, step_size:int, step:int):\n",
    "    X_window, y_window = sliding_window(X, window_length, step_size, step)\n",
    "    return calc_lrp(X_window), y_window\n",
    "\n",
    "\n",
    "\n",
    "######################## MNE CSP transform logic\n",
    "\n",
    "#Constants to save last-trained CSP objects\n",
    "# and dictionary of saved CSP objects for later use\n",
    "csp_transformer = mne.decoding.CSP()\n",
    "csp_dict = {}\n",
    "\n",
    "def csp_transform(X:np.ndarray, y:np.ndarray=None, n_components:int=None, transformer_label:str=None):\n",
    "    global csp_transformer\n",
    "    global csp_dict\n",
    "    dim = X.shape\n",
    "    X_shaped = X.reshape(dim[2], dim[0], dim[1])\n",
    "    if y is not None:\n",
    "        if n_components is not None:\n",
    "            csp_transformer = mne.decoding.CSP(n_components)\n",
    "        else:\n",
    "            csp_transformer = mne.decoding.CSP()\n",
    "        #Supress lengthy print statements from CSP\n",
    "                    #WARNING: This will supress all warnings and errors. ONLY USE IF CODE HAS BEEN TESTED\n",
    "                    # AND IT IS KNOWN THAT IT WILL NOT CRASH DURING THE FITTING PROCEDURE \n",
    "        with open(os.devnull, \"w\") as f, contextlib.redirect_stdout(f):\n",
    "            csp_transformer.fit(X_shaped, y)\n",
    "        if transformer_label is not None:\n",
    "            csp_dict[transformer_label] = csp_transformer\n",
    "        return None        \n",
    "    else:\n",
    "        #Supress lengthy print statements from CSP\n",
    "                    #WARNING: This will supress all warnings and errors. ONLY USE IF CODE HAS BEEN TESTED\n",
    "                    # AND IT IS KNOWN THAT IT WILL NOT CRASH DURING THE FITTING PROCEDURE \n",
    "        with open(os.devnull, \"w\") as f, contextlib.redirect_stdout(f):\n",
    "            if transformer_label is not None:\n",
    "                return csp_dict[transformer_label].transform(X_shaped)\n",
    "            else:\n",
    "                return csp_transformer.transform(X_shaped)\n",
    "\n",
    "def sliding_csp_transform(X:np.ndarray,\n",
    "                          window_length:int, \n",
    "                          step_size:int,\n",
    "                          step:int,\n",
    "                          y:np.ndarray=None,\n",
    "                          n_components:int=None,\n",
    "                          transformer_label:str=None,\n",
    "                          refit_csp=False):\n",
    "    X_window, y_window = sliding_window(X, window_length, step_size, step)\n",
    "    if refit_csp:\n",
    "        csp_transform(X_window, y_window, n_components, transformer_label)\n",
    "    return csp_transform(X_window, transformer_label=transformer_label), y_window\n",
    "    \n",
    "def sliding_csp_fit_transform(X:np.ndarray,\n",
    "                              window_length:int,\n",
    "                              step_size:int,\n",
    "                              step:int,\n",
    "                              y:np.ndarray,\n",
    "                              n_components:int=None,\n",
    "                              transformer_label:str=None):\n",
    "    X_window, y_window = sliding_window(X, window_length, step_size, step)\n",
    "    X_tr, X_ts, y_tr, y_ts = train_test_split(X_window, y_window, train_size=0.3)\n",
    "    csp_transform(X_tr, y_tr, n_components, transfomer_label)\n",
    "    return csp_transform(X_ts), y_ts, X_tr, y_tr\n",
    "    \n",
    "######################################### Data Formatting Logic ################################################\n",
    "def Format(X:np.ndarray, \n",
    "           y:np.ndarray,  \n",
    "           reduction_method:function, \n",
    "           reduction_method_args=None,\n",
    "           trials_in_A:int=100):\n",
    "    if type(reduction_method_args) == dict:\n",
    "        X_reduced = reduction_method(X, **reduction_method_args)\n",
    "    elif type(reduction_method_args) == list:\n",
    "        X_reduced = reduction_method(X, *reduction_method_args)\n",
    "    else:\n",
    "        X_reduced = reduction_method(X)\n",
    "    condition_A_data_dict, condition_B_data_dict = condition_split(X_reduced, y, trials_in_A)\n",
    "    return condition_A_data_dict, condition_B_data_dict\n",
    "\n",
    "def condition_split(X:np.ndarray, y:np.ndarray, trials_in_A:int):\n",
    "    AX, BX = X[:trials_in_A], X[trials_in_A:]\n",
    "    Ay, By = y[:trials_in_A], y[trials_in_A:]\n",
    "    A_dict = {'X': AX, 'y': Ay}\n",
    "    B_dict = {'X': BX, 'y': By}\n",
    "    return A_dict, B_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-antarctica",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-excess",
   "metadata": {},
   "source": [
    "#### Read in Hyperparameter Tuning Data ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "careful-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat('../Data/data_cube_subject1.mat')\n",
    "channel_labels = sio.loadmat('../Data/channel_label.mat')\n",
    "data_cube = data['data_cube']\n",
    "data_labels = data['event_label'].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "structural-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide data into CSP tuning and Hyperparameter Tuning Data\n",
    "data_cube.shape\n",
    "X_csp = data_cube[:,:,80:120]\n",
    "y_csp = data_labels[80:120]\n",
    "X_param_csp = np.vstack([data_cube[:,:,:80], data_cube[:,:,120:]])\n",
    "y_param_csp = np.hstack([data_labels[:80],data_labels[120:]])\n",
    "\n",
    "#fit CSP to proper data and save CSP object\n",
    "csp_transform(X_csp, y_csp, transformer_label='hyperparam_tune')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-steal",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning Constants ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "scientific-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter dictionaries for use in grid search\n",
    "ada_params = {\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'learning_rate': [x/20 for x in range(1,21)],\n",
    "    'algorithm': ['SAMME', 'SAMME.R']\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': (None, 10, 50, 100),\n",
    "    'min_samples_split': [2, 4, 5],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ('auto', 'sqrt', 'log2', None),\n",
    "    'min_impurity_decrease': (0.0, 0.5)\n",
    "}\n",
    "\n",
    "lda_params = {\n",
    "    'solver': ['svd','lsqr','eigen'],\n",
    "    'shrinkage': ['auto',None],\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': np.logspace(-3,2,6),\n",
    "    'kernel': ['linear','poly','rbf','sigmoid'],\n",
    "    'degree': [2,3,4],\n",
    "    'gamma': ['scale', 'auto'] + list(np.logspace(-3,3,6)),\n",
    "    'shrinking': [True, False],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "#Dictionary of classifiers and hyperparemeter selections\n",
    "clfs = {\n",
    "    'LDA': LDA(),\n",
    "    'SVM': SVC(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'RandomForestClassifier': rf_params,\n",
    "    'AdaBoostClassifier': ada_params,\n",
    "    'LDA': lda_params,\n",
    "    'SVM': svm_params\n",
    "}\n",
    "\n",
    "#data dimensionality reduction methods to opitmize for\n",
    "    #note that csp transform will use n_components=4 for model hyperparameter tuning\n",
    "    # n_components will be finalized in another round of cross-validation\n",
    "    # runtime to validate all combinations of n_components and model hyperparameters too long\n",
    "    # for our current computational capacity so this will have to do\n",
    "reduction_methods = {\n",
    "    'lrp': calc_lrp,\n",
    "    'csp': lambda X: csp_transform(X, transformer_label='hyperparam_tune')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-script",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning Functions ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ignored-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tune_multiple_models(data_matrix:np.ndarray, \n",
    "                         data_labels:np.ndarray, \n",
    "                         clf_list:list=None, \n",
    "                         reduction_method_list:list=None):\n",
    "    if clf_list==None:\n",
    "        clf_list = [key for key in clfs]\n",
    "    if reduction_method_list==None:\n",
    "        reduction_method_list = [key for key in reduction_methods]\n",
    "    tuned_models = []\n",
    "    for clf_ident in clf_list:\n",
    "        for reduction_method_ident in reduction_method_list:\n",
    "            tuned_models.append(tune_model(data_matrix, \n",
    "                                           data_labels, \n",
    "                                           clf_ident, \n",
    "                                           reduction_method_ident) )\n",
    "    return tuned_models\n",
    "\n",
    "def tune_model(data_matrix:np.ndarray, \n",
    "               data_labels:np.ndarray,\n",
    "               clf_ident:str, \n",
    "               reduction_method_ident:str):\n",
    "    #Let user know which model is being tuned\n",
    "    print('Hyperparameter tuning:', clf_ident, 'using dimensionality reducuction:', reduction_method_ident)\n",
    "    #obtain classifier, hyperparameters from corresponding dictionaries\n",
    "    clf = clfs[clf_ident]\n",
    "    hyperparam_dict = params[clf_ident]\n",
    "    reduction_method = reduction_methods[reduction_method_ident]\n",
    "    #apply dimensionality reduction to data and split into different experiment classes\n",
    "    #For model hyperparameter tuning, do not separate A and B conditions\n",
    "    #TODO: When we have more data, it might be better to tune separate models for A and B classes\n",
    "        #At the moment there is not enough data to tune each class independently\n",
    "    _, data_dict = Format(data_matrix, data_labels, reduction_method, trials_in_A=0)\n",
    "    #tune model\n",
    "    X = data_dict['X']\n",
    "    y = data_dict['y']\n",
    "    clf_mod = GridSearchCV(clf, hyperparam_dict, n_jobs=7)\n",
    "    clf_mod.fit(X,y)\n",
    "    print('Done.')\n",
    "    return {\n",
    "        'clf_type': clf_ident,\n",
    "        'reduction_method': reduction_method_ident,\n",
    "        'clf': clf_mod\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-bradley",
   "metadata": {},
   "source": [
    "#### Tune n_components for CSP Data Reduction ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "yellow-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_component_candidates = [x for x in range(1,64)]\n",
    "    \n",
    "def tune_csp_args_cv(csp_models:list, \n",
    "                  n_component_list=list(range(1,64)), \n",
    "                  X:np.ndarray=data_cube, \n",
    "                  y:np.ndarray=data_labels,\n",
    "                  n_folds=5):\n",
    "    for clf_dict in csp_models:\n",
    "        if clf_dict['reduction_method']!='csp':\n",
    "            continue\n",
    "        if 'reduction_method_args' not in clf_dict:\n",
    "            clf_dict['reduction_method_args'] = {}\n",
    "        params = clf_dict['clf'].best_params_\n",
    "        mod = clf_dict['clf'].estimator\n",
    "        mod.set_params(**params)\n",
    "        best_n = None\n",
    "        best_acc = -1\n",
    "        for n_components in n_component_list:\n",
    "            acc_list = []\n",
    "            cv = KFold(shuffle=True, n_splits=n_folds)\n",
    "            for train_idx, test_idx in cv.split(y):\n",
    "                #fit csp transform\n",
    "                 #Supress lengthy print statements from CSP\n",
    "                    #WARNING: This will supress all warnings and errors. ONLY use if code has been\n",
    "                    # tested and is known to not crash during the transform.\n",
    "                with open(os.devnull, \"w\") as f, contextlib.redirect_stdout(f):\n",
    "                    csp_transform(X[:,:,train_idx], y[train_idx], n_components)\n",
    "                #Transform data\n",
    "                #Supress lengthy print statements from CSP\n",
    "                #WARNING: This will supress all warnings and errors ONLY use if code has been\n",
    "                    # tested and is known to not crash during the transform.\n",
    "                with open(os.devnull, \"w\") as f, contextlib.redirect_stdout(f):\n",
    "                    _, data_dict = Format(X, y, csp_transform, trials_in_A=0)\n",
    "                X_formatted, y_formatted = data_dict['X'], data_dict['y']\n",
    "                X_tr, y_tr = X_formatted[train_idx], y_formatted[train_idx]\n",
    "                X_ts, y_ts = X_formatted[test_idx], y_formatted[test_idx]\n",
    "                mod.fit(X_tr, y_tr)\n",
    "                y_pred = mod.predict(X_ts)\n",
    "                acc_list.append(accuracy_score(y_ts, y_pred))\n",
    "            ave_acc = sum(acc_list)/len(acc_list)\n",
    "            if ave_acc > best_acc:\n",
    "                best_acc = ave_acc\n",
    "                best_n = n_components\n",
    "        clf_dict['reduction_method_args']['n_components'] = best_n\n",
    "    return csp_models\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-produce",
   "metadata": {},
   "source": [
    "## Model Evaluation And Selection ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-nutrition",
   "metadata": {},
   "source": [
    "## Model Evaluation Functions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "laughing-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_data(X_train:np.ndarray, \n",
    "                 X_test:np.ndarray, \n",
    "                 y_train:np.ndarray, \n",
    "                 reduction_method:function, \n",
    "                 reduction_method_args:dict):\n",
    "    #determine if reduction method requires fitting on training data\n",
    "    #the following method determines if reduction method requires data labels, if it does\n",
    "    # this implies the reduction method has to be fit to the data\n",
    "    if 'y' in list(inspect.signature(reduction_method).parameters):\n",
    "        #fit reduction method to the data\n",
    "        reduction_method(X_train, y=y_train, **reduction_method_args)\n",
    "    #do dimensionality reduction on both training and testing data\n",
    "    X_tr = reduction_method(X_train, **reduction_method_args)\n",
    "    X_ts = reduction_method(X_test, **reduction_method_args)\n",
    "    return X_tr, X_ts\n",
    "    \n",
    "\n",
    "\n",
    "def evaluate_model_single_condition(clf_dict:dict, \n",
    "                                    X:np.ndarray, \n",
    "                                    y:np.ndarray, \n",
    "                                    reduction_method:function, \n",
    "                                    reduction_method_args:dict=None, \n",
    "                                    n_folds:int=5):\n",
    "    #array of trial accuracies\n",
    "    acc_list = []\n",
    "    #obtain reduction method arguments if not provided in parameters\n",
    "    if reduction_method_args is None:\n",
    "        if 'reduction_method_args' not in clf_dict:\n",
    "            reduction_method_args = {}\n",
    "        else:\n",
    "            reduction_method_args = clf_dict['reduction_method_args']\n",
    "    #perform k-fold cross-validation to estimate model accuracy\n",
    "    cv = KFold(shuffle=True, n_splits=n_folds)\n",
    "    for train_idx, test_idx in cv.split(y):\n",
    "        #split data into train-test partitions\n",
    "        X_tr, X_ts = X[:,:,train_idx], X[:,:,test_idx]\n",
    "        y_tr, y_ts = y[train_idx], y[test_idx]\n",
    "        #do the dimensionality-reducing transformation outlined by reduction_method\n",
    "        data = (X_tr, X_ts, y_tr)\n",
    "        X_tr, X_ts = prepare_data(*data, reduction_method, reduction_method_args)\n",
    "        #assemble and train classifier\n",
    "        params = clf_dict['clf'].best_params_\n",
    "        mod = clf_dict['clf'].estimator\n",
    "        mod.set_params(**params)\n",
    "        mod.fit(X_tr, y_tr)\n",
    "        #predict and obtain accuracy score\n",
    "        y_pred = mod.predict(X_ts)\n",
    "        acc_list.append(accuracy_score(y_ts, y_pred))\n",
    "    return np.array(acc_list)\n",
    "\n",
    "def evaluate_model_both_conditions(clf_dict:dict, \n",
    "                                   X:np.ndarray, \n",
    "                                   y:np.ndarray, \n",
    "                                   trials_in_A:int,\n",
    "                                   reduction_method:function, \n",
    "                                   reduction_method_args:dict=None, \n",
    "                                   n_folds:int=5):\n",
    "    #collect parameters which do not vary between A and B conditions\n",
    "    test_params = [reduction_method, reduction_method_args, n_folds]\n",
    "    #obtain accuracy score on A and B separately\n",
    "    A_acc = evaluate_model_single_condition(clf_dict, X[:,:,:trials_in_A], y[:trials_in_A], *test_params)\n",
    "    B_acc = evaluate_model_single_condition(clf_dict, X[:,:,trials_in_A:], y[trials_in_A:], *test_params)\n",
    "    return A_acc, B_acc\n",
    "\n",
    "def evaluate_models(clfs:list, \n",
    "                    X:np.ndarray, \n",
    "                    y:np.ndarray, \n",
    "                    trials_in_A:int, \n",
    "                    reduction_methods:dict, \n",
    "                    reduction_method_arg_list:dict=None,\n",
    "                    n_folds:int=5):\n",
    "    #assemble test conditions, test conditions consist of a tuple (classifier_dict, reduction_method, reduction_method_args)\n",
    "    if reduction_method_arg_list is None:\n",
    "        reduction_method_arg_list = { method:None for method in reduction_methods }\n",
    "    for clf in clfs:\n",
    "        reduction_method = reduction_methods[clf['reduction_method']]\n",
    "        reduction_method_args = reduction_method_arg_list[clf['reduction_method']]\n",
    "        A_acc, B_acc = evaluate_model_both_conditions(clf, X, y, trials_in_A, reduction_method, reduction_method_args, n_folds)\n",
    "        clf['A_accuracy'] = A_acc\n",
    "        clf['B_accuracy'] = B_acc\n",
    "    return clfs\n",
    "                             \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-cowboy",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./bin/clfs.p','rb') as clf_pickle_file:\n",
    "    tuned_models = pickle.load(clf_pickle_file)\n",
    "\n",
    "tuned_models[1]['n_components'] = 6\n",
    "tuned_models[3]['n_components'] = 6\n",
    "\n",
    "dimensionality_reduction_methods = {'lsp': calc_lrp, 'csp': csp_transform}\n",
    "evaluate_models(tuned_models, data_cube, data_labels, 100, dimensionality_reduction_methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-establishment",
   "metadata": {},
   "source": [
    "## End Function Definitions. Begin Model Analysis ##\n",
    "### Tune Hyperparameters ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "stunning-return",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter tuning: LDA using dimensionality reducuction: lrp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dominic/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [  nan 0.715 0.715 0.69  0.57    nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Hyperparameter tuning: LDA using dimensionality reducuction: csp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dominic/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [  nan 0.52  0.52  0.515 0.515 0.515]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Hyperparameter tuning: SVM using dimensionality reducuction: lrp\n",
      "Done.\n",
      "Hyperparameter tuning: SVM using dimensionality reducuction: csp\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-1bb4e3644b83>\u001b[0m in \u001b[0;36mtune_multiple_models\u001b[0;34m(data_matrix, data_labels, clf_list, reduction_method_list)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mclf_ident\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclf_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mreduction_method_ident\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreduction_method_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             tuned_models.append(tune_model(data_matrix, \n\u001b[0m\u001b[1;32m     13\u001b[0m                                            \u001b[0mdata_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                            \u001b[0mclf_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-1bb4e3644b83>\u001b[0m in \u001b[0;36mtune_model\u001b[0;34m(data_matrix, data_labels, clf_ident, reduction_method_ident)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mclf_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparam_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mclf_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     return {\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# #Tune hyperparameters. WARNING: This block takes approximately 5 hours to complete on 7 cores\n",
    "tuned_clfs = tune_multiple_models(data_cube, data_labels)\n",
    "with open('./bin/clfs.p','wb') as clf_pickle_file:\n",
    "    pickle.dump(tuned_clfs, clf_pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-buffalo",
   "metadata": {},
   "source": [
    "### Tune n_components for CSP dimensionality reduction ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "veterinary-transaction",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tuned_clfs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tuned_clfs' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#This block runs in 2 hours on 3 cores\n",
    "tune_csp_args_cv(tuned_clfs, n_component_list=list(range(1,64)))\n",
    "with open('./bin/clfs.p','wb') as clf_pickle_file:\n",
    "    pickle.dump(tuned_clfs, clf_pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-brush",
   "metadata": {},
   "source": [
    "### Evaluate All Models and Select Best Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "female-greeting",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tuned_clfs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tuned_clfs' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dimensionality_reduction_methods = {'lrp': calc_lrp, 'csp': csp_transform}\n",
    "evaluate_models(tuned_clfs, data_cube, data_labels, 100, dimensionality_reduction_methods)\n",
    "with open('./bin/clfs.p','wb') as clf_pickle_file:\n",
    "    pickle.dump(tuned_clfs, clf_pickle_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
