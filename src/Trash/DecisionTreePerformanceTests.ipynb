{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "disabled-married",
   "metadata": {},
   "source": [
    "# Evaluation of Decision Tree Algoithm Performance #\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-preliminary",
   "metadata": {},
   "source": [
    "## Import Statements ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "julian-scholarship",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-paradise",
   "metadata": {},
   "source": [
    "## Constant Variable Definitions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "worse-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-jesus",
   "metadata": {},
   "source": [
    "## Function Definitions ##\n",
    "### Data Formatting and Preparation Functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "precise-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Format(X:np.ndarray, \n",
    "           y:np.ndarray, \n",
    "           trials_per_condition:int=100, \n",
    "           reduction_method:str= 'Ave_over_samples'):\n",
    "    \"\"\"\n",
    "    Functionality: Method prepares data for usage in a ML algorithm. After feeding X,y through this algorithm, you can expect:\n",
    "        X and y will be split according to the different experiment conditions. Location of split is determined by trials_per_condition\n",
    "        X will have its number of dimensions reduced by one, according to the reducion method specified. Also, output data will be transposed\n",
    "            so that the first index is the number of trials.\n",
    "    Param:\n",
    "        X:: ndarray of unlabeled EEG data with dimensions (channels, samples, trials). \n",
    "        y:: ndarray of data labels for X with dimensions (trials).\n",
    "        trials_per_condition:: number of trials done for each condition. Method assumes equal number of trials per condition\n",
    "        reduction_method:: function with signature (channels x samples x trials)darray ==> ndarray, where the co-domain contains arrays of one fewer dimension than the domain\n",
    "    Returns:\n",
    "        X_by_classes_reduced:: Dictionary with keys A,B and values of dimensionality reduced X separated by condition type A or B. The first index of arrays in X_by_classes_reduced\n",
    "                                    will correspond to the trial number. The second index will correspond to a value which depends on the reduction_method.\n",
    "        y_by_classes:: Dictionary with keys A,B and values of y separated by condition type A or B.\n",
    "    \"\"\"\n",
    "    X_by_classes, y_by_classes = class_split(X,y, trials_per_condition)\n",
    "    reduce = reduction_methods[reduction_method]\n",
    "    X_by_classes_reduced = {typ: reduce(X_by_classes[typ]).T\\\n",
    "                            for typ in X_by_classes}\n",
    "    return X_by_classes_reduced, y_by_classes\n",
    "\n",
    "def class_split(X:np.ndarray, y:np.ndarray, trials_per_condition:int):\n",
    "    \"\"\"\n",
    "    Helper Method to Format, separates X and y into condition types\n",
    "    \"\"\"\n",
    "    AX, BX = X[:,:,:trials_per_condition], X[:,:,trials_per_condition:]\n",
    "    Ay, By = y[:trials_per_condition], y[trials_per_condition:]\n",
    "    X_dict, y_dict = {'A': AX, 'B':BX}, {'A':Ay, 'B':By}\n",
    "    return X_dict, y_dict\n",
    "#Reduction methods\n",
    "#All reduction methods should assume a np.ndarray of shape (channels x samples x trials)\n",
    "#All reduction methods should return a np.ndarray of shape (dim x trials), where dim depends on the reduction method\n",
    "reduction_methods = {\n",
    "    'Ave_over_channels': lambda X: np.mean(X,0),\n",
    "    'Ave_over_samples': lambda X: np.mean(X,1),\n",
    "    'Ave_over_samples_ch24_ch8': lambda X: (X[23,:] - X[7,:])\n",
    "}\n",
    "\n",
    "def split(X,y, train_idx):\n",
    "    all_idx = list(range(len(X['A'])))\n",
    "    test_idx = [idx for idx in all_idx if idx not in train_idx]\n",
    "    X_train = {'A': X['A'][train_idx], 'B':X['B'][train_idx]}\n",
    "    y_train = {'A': y['A'][train_idx], 'B':y['B'][train_idx]}\n",
    "    X_test = {'A': X['A'][test_idx], 'B':X['B'][test_idx]}\n",
    "    y_test = {'A': y['A'][test_idx], 'B':y['B'][test_idx]}\n",
    "    test_dict = {'X': X_test, 'y': y_test}\n",
    "    train_dict = {'X': X_train, 'y': y_train}\n",
    "    return {'test': test_dict, 'train': train_dict}\n",
    "\n",
    "def train_test_partition(X_dict, y_dict, test_size=0.3, random_state=None):\n",
    "    all_idx = list(range(X_dict['A'].shape[0]))\n",
    "    train_idx, test_idx = train_test_split(all_idx, test_size=test_size, random_state=random_state)\n",
    "    #make splits\n",
    "    X_dict_train = {key:X_dict[key][train_idx] for key in X_dict}\n",
    "    X_dict_test = {key:X_dict[key][test_idx] for key in X_dict}\n",
    "    y_dict_train = {key:y_dict[key][train_idx] for key in y_dict}\n",
    "    y_dict_test = {key:y_dict[key][test_idx] for key in y_dict}\n",
    "    \n",
    "    return (X_dict_train, \n",
    "            X_dict_test, \n",
    "            y_dict_train, \n",
    "            y_dict_test, \n",
    "            train_idx, \n",
    "            test_idx)\n",
    "\n",
    "def recombine_test_train_partitions(X_train_dict, y_train_dict, X_test_dict, y_test_dict):\n",
    "    XA_train, XB_train = X_train_dict['A'], X_train_dict['B']\n",
    "    yA_train, yB_train = y_train_dict['A'], y_train_dict['B']\n",
    "    XA_test, XB_test = X_test_dict['A'], X_test_dict['B']\n",
    "    yA_test, yB_test = y_test_dict['A'], y_test_dict['B']\n",
    "    XA = np.vstack([XA_train, XA_test])\n",
    "    XB = np.vstack([XB_train, XB_test])\n",
    "    yA = np.hstack([yA_train, yA_test])\n",
    "    yB = np.hstack([yB_train, yB_test])\n",
    "    X_dict = {'A': XA, 'B': XB}\n",
    "    y_dict = {'A': yA, 'B': yB}\n",
    "    return X_dict, y_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-october",
   "metadata": {},
   "source": [
    "### Model Training Function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "crucial-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function used to re train model only when necessary\n",
    "#function compares training data to training data model was last\n",
    "#trained with. Only retrains if differences between old and new training data \n",
    "#are found\n",
    "last_X_train = np.array([])\n",
    "last_y_train = np.array([])\n",
    "last_clf_params = None\n",
    "last_clf = None\n",
    "\n",
    "def retrain(clf:dict, X:np.ndarray, y:np.ndarray):\n",
    "    global last_X_train\n",
    "    global last_y_train\n",
    "    global last_clf_params\n",
    "    global last_clf\n",
    "    #exeption prevention\n",
    "    #if no training data is given, return input classifier\n",
    "    if X is None:\n",
    "        return clf['clf']\n",
    "    #all of the following conditions in the following list must be \n",
    "    # for previously trained model to be usable\n",
    "    if last_X_train.shape == X.shape:\n",
    "        if clf['clf'].best_params_ == last_clf_params:\n",
    "            if (last_X_train == X).all():\n",
    "                if (last_y_train==y).all():\n",
    "                    return last_clf\n",
    "    clf_type = clf['clf_type']\n",
    "    last_clf_params = clf['clf'].best_params_\n",
    "    clf_new = clfs[clf_type]\n",
    "    clf_new.set_params(**last_clf_params)\n",
    "    clf_new.fit(X, y)\n",
    "    last_clf = clf_new\n",
    "    last_X_train = X\n",
    "    last_y_train = y\n",
    "    return clf_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-drilling",
   "metadata": {},
   "source": [
    "### Model Evaluation Functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "floral-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_condition(clf, \n",
    "                   X_test:np.ndarray,\n",
    "                   y_test:np.ndarray,\n",
    "                   X_train:np.ndarray=None,\n",
    "                   y_train:np.ndarray=None,\n",
    "                   n_rounds:int=1,\n",
    "                   n_train_sample_bootstrap:int=None,\n",
    "                   n_test_sample_bootstrap:int=None):\n",
    "    aucs = [] #return variable\n",
    "    X, y = None, None #placeholder variables for features and labels\n",
    "    for n in range(n_rounds):\n",
    "        try:\n",
    "            X,y = bootstrap(X_train, y_train, n_train_sample_bootstrap)\n",
    "            mod = retrain(clf, X, y)\n",
    "            mod1 = RandomForestClassifier()\n",
    "            mod1.fit(X,y)\n",
    "            X,y = bootstrap(X_test, y_test, n_test_sample_bootstrap)\n",
    "            y_pred = mod.predict_proba(X)\n",
    "            aucs.append(roc_auc_score(y,y_pred[:,1]))\n",
    "        except ValueError:\n",
    "            aucs.append(-1)\n",
    "    return np.array(aucs)\n",
    "        \n",
    "def evaluate_model(clf:dict,\n",
    "                  X_test_dict:dict,\n",
    "                  y_test_dict:dict,\n",
    "                  X_train_dict:dict=None,\n",
    "                  y_train_dict:dict=None,\n",
    "                  n_rounds_bootstrap:int=1,\n",
    "                  n_train_sample_bootstrap:int=None,\n",
    "                  n_test_sample_bootstrap:int=None,\n",
    "                  redo_test_train_partition:bool=False,\n",
    "                  train_AB_separately:bool=False):   \n",
    "    if redo_test_train_partition:\n",
    "        if X_train_dict is not None:\n",
    "            X_dict, y_dict = recombine_test_train_partitions(X_train_dict,\n",
    "                                                             y_train_dict, \n",
    "                                                             X_test_dict, \n",
    "                                                             y_test_dict)\n",
    "        else:\n",
    "            X_dict, y_dict = X_test_dict, y_test_dict\n",
    "        X_train_dict, X_test_dict, y_train_dict, y_test_dict, _, _ = train_test_partition(X_dict, y_dict)\n",
    "    if train_AB_separately:\n",
    "        XA_train, XB_train = X_train_dict['A'], X_train_dict['B']\n",
    "        yA_train, yB_train = y_train_dict['A'], y_train_dict['B']\n",
    "    else:\n",
    "        if X_train_dict is None:\n",
    "            XA_train, XB_train, yA_train, yB_train = None, None, None, None\n",
    "        else:\n",
    "            XA_train = np.vstack([X_train_dict['A'], X_train_dict['B']])\n",
    "            XB_train = XA_train\n",
    "            yA_train = np.hstack([y_train_dict['A'], y_train_dict['B']])\n",
    "            yB_train = yA_train\n",
    "    A_aucs = evaluate_model_on_condition(clf,\n",
    "                                         X_test_dict['A'],\n",
    "                                         y_test_dict['A'],\n",
    "                                         XA_train,\n",
    "                                         yA_train,\n",
    "                                         n_rounds_bootstrap,\n",
    "                                         n_train_sample_bootstrap,\n",
    "                                         n_test_sample_bootstrap)\n",
    "    B_aucs = evaluate_model_on_condition(clf,\n",
    "                                         X_test_dict['B'],\n",
    "                                         y_test_dict['B'],\n",
    "                                         XB_train,\n",
    "                                         yB_train,\n",
    "                                         n_rounds_bootstrap,\n",
    "                                         n_train_sample_bootstrap,\n",
    "                                         n_test_sample_bootstrap)\n",
    "    return {'A': A_aucs, 'B': B_aucs}\n",
    "    \n",
    "\n",
    "#The following function calls evaluate_model on the specified \n",
    "# input, and returns an auc distribution in a dictionary along\n",
    "# with information speciyfing which model was tested\n",
    "def get_model_eval(clf:dict,\n",
    "                   X_test_dict:dict,\n",
    "                   y_test_dict:dict,\n",
    "                   X_train_dict:dict=None,\n",
    "                   y_train_dict:dict=None,\n",
    "                   n_rounds_bootstrap:int=1,\n",
    "                   n_train_sample_bootstrap:int=None,\n",
    "                   n_test_sample_bootstrap:int=None,\n",
    "                   n_rounds_test_train_split:int=None,\n",
    "                   separate_AB_models:bool=False):\n",
    "    output_dict = {'clf_type': clf['clf_type'],\n",
    "                   'reduction_method': clf['reduction_method'],\n",
    "                   'bootstrapped_training_data': n_train_sample_bootstrap,\n",
    "                   'n_rounds_test_train_split': n_rounds_test_train_split,\n",
    "                   'separate_AB_models' : separate_AB_models}\n",
    "    if n_rounds_test_train_split is None:\n",
    "        output_dict['aucs'] = evaluate_model(clf, \n",
    "                                             X_test_dict,\n",
    "                                             y_test_dict,\n",
    "                                             X_train_dict,\n",
    "                                             y_train_dict,\n",
    "                                             n_rounds_bootstrap,\n",
    "                                             n_train_sample_bootstrap,\n",
    "                                             n_test_sample_bootstrap,\n",
    "                                             False,\n",
    "                                             separate_AB_models)\n",
    "    else:\n",
    "        auc_dict = {'A': np.array([]), 'B': np.array([])}\n",
    "        for n in range(n_rounds_test_train_split):\n",
    "            auc_i = evaluate_model(clf, \n",
    "                                   X_test_dict,\n",
    "                                   y_test_dict,\n",
    "                                   X_train_dict,\n",
    "                                   y_train_dict,\n",
    "                                   n_rounds_bootstrap,\n",
    "                                   n_train_sample_bootstrap,\n",
    "                                   n_test_sample_bootstrap,\n",
    "                                   True,\n",
    "                                   separate_AB_models)\n",
    "            auc_dict['A'] = np.append(auc_dict['A'], auc_i['A'])\n",
    "            auc_dict['B'] = np.append(auc_dict['B'], auc_i['B'])\n",
    "        output_dict['aucs'] = auc_dict\n",
    "        \n",
    "    return output_dict\n",
    "\n",
    "        \n",
    "\n",
    "def bootstrap(X,y, n_sample_bootstrap):\n",
    "    if X is None or y is None or n_sample_bootstrap is None:\n",
    "        return X, y\n",
    "    bootstrap_idx = np.random.randint(X.shape[0], size=n_sample_bootstrap)\n",
    "    return X[bootstrap_idx], y[bootstrap_idx]\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "demonstrated-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_tests(data_matrix:np.ndarray, \n",
    "                       data_labels:np.ndarray,\n",
    "                       clf_list:list, \n",
    "                       n_rounds_bootstrap:int=300, \n",
    "                       n_train_sample_bootstrap:int=500, \n",
    "                       n_test_sample_bootstrap:int=30, \n",
    "                       n_rounds_test_train_split:int=300):\n",
    "    test_results = []\n",
    "    #define testing options\n",
    "    bootstrap_cond = (n_train_sample_bootstrap, None)\n",
    "    redo_test_train_cond = (n_rounds_test_train_split, None)\n",
    "    separate_AB_model_cond = (True, False)\n",
    "    for clf in clf_list:\n",
    "        reduction_method = clf['reduction_method']\n",
    "        train_idx = clf['train_idx']\n",
    "        for training_bootstraps in bootstrap_cond:\n",
    "            for splits in redo_test_train_cond:\n",
    "                if splits is not None:\n",
    "                    bootstrap_rounds = 1\n",
    "                else:\n",
    "                    bootstrap_rounds = n_rounds_bootstrap\n",
    "                for AB_model in separate_AB_model_cond:\n",
    "                    X,y = Format(data_matrix, data_labels, reduction_method=reduction_method)\n",
    "                    data_dict = split(X, y, train_idx)\n",
    "                    parameters = {\n",
    "                        'clf': clf,\n",
    "                        'X_test_dict': data_dict['test']['X'],\n",
    "                        'y_test_dict': data_dict['test']['y'],\n",
    "                        'X_train_dict': data_dict['train']['X'],\n",
    "                        'y_train_dict': data_dict['train']['y'],\n",
    "                        'n_rounds_bootstrap': bootstrap_rounds,\n",
    "                        'n_train_sample_bootstrap': training_bootstraps,\n",
    "                        'n_test_sample_bootstrap': n_test_sample_bootstrap,\n",
    "                        'n_rounds_test_train_split': splits,\n",
    "                        'separate_AB_models': AB_model\n",
    "                    }\n",
    "                    test_results.append(get_model_eval(**parameters))\n",
    "                    \n",
    "    return test_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-commerce",
   "metadata": {},
   "source": [
    "## Read in and prepare Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "baking-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_models = None\n",
    "with open('./clfs.p', 'rb') as models:\n",
    "    fitted_models = pickle.load(models)\n",
    "for mod in fitted_models:\n",
    "    mod['clf'].best_params_['random_state'] = None\n",
    "\n",
    "data = sio.loadmat('../Data/data_cube_subject1.mat')\n",
    "channel_labels = sio.loadmat('../Data/channel_label.mat')\n",
    "data_matrix = data['data_cube']\n",
    "data_labels = data['event_label'].reshape((200,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-frame",
   "metadata": {},
   "source": [
    "## Test Models ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "collect-savage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-33f101c448d4>\u001b[0m in \u001b[0;36mrun_model_tests\u001b[0;34m(data_matrix, data_labels, clf_list, n_rounds_bootstrap, n_train_sample_bootstrap, n_test_sample_bootstrap, n_rounds_test_train_split)\u001b[0m\n\u001b[1;32m     35\u001b[0m                         \u001b[0;34m'separate_AB_models'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAB_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                     }\n\u001b[0;32m---> 37\u001b[0;31m                     \u001b[0mtest_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_model_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtest_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-d6fa4dde70b0>\u001b[0m in \u001b[0;36mget_model_eval\u001b[0;34m(clf, X_test_dict, y_test_dict, X_train_dict, y_train_dict, n_rounds_bootstrap, n_train_sample_bootstrap, n_test_sample_bootstrap, n_rounds_test_train_split, separate_AB_models)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mauc_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'B'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_rounds_test_train_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             auc_i = evaluate_model(clf, \n\u001b[0m\u001b[1;32m    107\u001b[0m                                    \u001b[0mX_test_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                                    \u001b[0my_test_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-d6fa4dde70b0>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(clf, X_test_dict, y_test_dict, X_train_dict, y_train_dict, n_rounds_bootstrap, n_train_sample_bootstrap, n_test_sample_bootstrap, redo_test_train_partition, train_AB_separately)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0myA_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0myB_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myA_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     A_aucs = evaluate_model_on_condition(clf,\n\u001b[0m\u001b[1;32m     56\u001b[0m                                          \u001b[0mX_test_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                                          \u001b[0my_test_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-d6fa4dde70b0>\u001b[0m in \u001b[0;36mevaluate_model_on_condition\u001b[0;34m(clf, X_test, y_test, X_train, y_train, n_rounds, n_train_sample_bootstrap, n_test_sample_bootstrap)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_rounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbootstrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_train_sample_bootstrap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mmod1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mmod1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-23f1b339682c>\u001b[0m in \u001b[0;36mretrain\u001b[0;34m(clf, X, y)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mclf_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mclf_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mlast_clf_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mclf_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mlast_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mlast_X_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m    388\u001b[0m                              \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'threads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    167\u001b[0m                                                         indices=indices)\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \"\"\"\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    899\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-bb58160640d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#save test results to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Data/test_results.p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresults_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_results' is not defined"
     ]
    }
   ],
   "source": [
    "%time test_results = run_model_tests(data_matrix, data_labels, fitted_models)\n",
    "\n",
    "#save test results to file\n",
    "with open('../Data/test_results.p', 'wb') as results_file:\n",
    "    pickle.dump(test_results, results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "equal-drain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 31s, sys: 312 ms, total: 1min 32s\n",
      "Wall time: 1min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'clf_type': 'RandomForestClassifier',\n",
       "  'reduction_method': 'Ave_over_samples_ch24_ch8',\n",
       "  'bootstrapped_training_data': 500,\n",
       "  'n_rounds_test_train_split': 3,\n",
       "  'separate_AB_models': True,\n",
       "  'aucs': {'A': array([0.6937799 , 0.88392857, 0.88392857]),\n",
       "   'B': array([0.84598214, 0.59330144, 0.52631579])}},\n",
       " {'clf_type': 'RandomForestClassifier',\n",
       "  'reduction_method': 'Ave_over_samples_ch24_ch8',\n",
       "  'bootstrapped_training_data': 500,\n",
       "  'n_rounds_test_train_split': 3,\n",
       "  'separate_AB_models': False,\n",
       "  'aucs': {'A': array([0.85267857, 0.74444444, 0.86444444]),\n",
       "   'B': array([0.92410714, 0.81100478, 0.95535714])}},\n",
       " {'clf_type': 'RandomForestClassifier',\n",
       "  'reduction_method': 'Ave_over_samples_ch24_ch8',\n",
       "  'bootstrapped_training_data': 500,\n",
       "  'n_rounds_test_train_split': None,\n",
       "  'separate_AB_models': True,\n",
       "  'aucs': {'A': array([0.96296296]), 'B': array([0.69444444])}},\n",
       " {'clf_type': 'RandomForestClassifier',\n",
       "  'reduction_method': 'Ave_over_samples_ch24_ch8',\n",
       "  'bootstrapped_training_data': 500,\n",
       "  'n_rounds_test_train_split': None,\n",
       "  'separate_AB_models': False,\n",
       "  'aucs': {'A': array([0.94642857]), 'B': array([0.88095238])}},\n",
       " {'clf_type': 'RandomForestClassifier',\n",
       "  'reduction_method': 'Ave_over_samples_ch24_ch8',\n",
       "  'bootstrapped_training_data': None,\n",
       "  'n_rounds_test_train_split': 3,\n",
       "  'separate_AB_models': True,\n",
       "  'aucs': {'A': array([0.95927602, 0.64285714, 0.85267857]),\n",
       "   'B': array([0.90045249, 0.60416667, 0.74776786])}},\n",
       " {'clf_type': 'RandomForestClassifier',\n",
       "  'reduction_method': 'Ave_over_samples_ch24_ch8',\n",
       "  'bootstrapped_training_data': None,\n",
       "  'n_rounds_test_train_split': 3,\n",
       "  'separate_AB_models': False,\n",
       "  'aucs': {'A': array([0.92533937, 0.79904306, 0.81473214]),\n",
       "   'B': array([0.4569378 , 0.63555556, 0.87037037])}},\n",
       " {'clf_type': 'RandomForestClassifier',\n",
       "  'reduction_method': 'Ave_over_samples_ch24_ch8',\n",
       "  'bootstrapped_training_data': None,\n",
       "  'n_rounds_test_train_split': None,\n",
       "  'separate_AB_models': True,\n",
       "  'aucs': {'A': array([0.74888889]), 'B': array([0.62669683])}},\n",
       " {'clf_type': 'RandomForestClassifier',\n",
       "  'reduction_method': 'Ave_over_samples_ch24_ch8',\n",
       "  'bootstrapped_training_data': None,\n",
       "  'n_rounds_test_train_split': None,\n",
       "  'separate_AB_models': False,\n",
       "  'aucs': {'A': array([0.86111111]), 'B': array([0.79513889])}},\n",
       " {'clf_type': 'AdaBoostClassifier',\n",
       "  'reduction_method': 'Ave_over_samples_ch24_ch8',\n",
       "  'bootstrapped_training_data': 500,\n",
       "  'n_rounds_test_train_split': 3,\n",
       "  'separate_AB_models': True,\n",
       "  'aucs': {'A': array([0.71428571, 0.7239819 , 0.83229814]),\n",
       "   'B': array([0.62200957, 0.68325792, 0.71493213])}},\n",
       " {'clf_type': 'AdaBoostClassifier',\n",
       "  'reduction_method': 'Ave_over_samples_ch24_ch8',\n",
       "  'bootstrapped_training_data': 500,\n",
       "  'n_rounds_test_train_split': 3,\n",
       "  'separate_AB_models': False,\n",
       "  'aucs': {'A': array([0.84      , 0.88235294, 0.58823529]),\n",
       "   'B': array([0.85972851, 0.7037037 , 0.84210526])}},\n",
       " {'clf_type': 'AdaBoostClassifier',\n",
       "  'reduction_method': 'Ave_over_samples_ch24_ch8',\n",
       "  'bootstrapped_training_data': 500,\n",
       "  'n_rounds_test_train_split': None,\n",
       "  'separate_AB_models': True,\n",
       "  'aucs': {'A': array([0.70982143]), 'B': array([0.71957672])}},\n",
       " {'clf_type': 'AdaBoostClassifier',\n",
       "  'reduction_method': 'Ave_over_samples_ch24_ch8',\n",
       "  'bootstrapped_training_data': 500,\n",
       "  'n_rounds_test_train_split': None,\n",
       "  'separate_AB_models': False,\n",
       "  'aucs': {'A': array([0.70601852]), 'B': array([0.70807453])}},\n",
       " {'clf_type': 'AdaBoostClassifier',\n",
       "  'reduction_method': 'Ave_over_samples_ch24_ch8',\n",
       "  'bootstrapped_training_data': None,\n",
       "  'n_rounds_test_train_split': 3,\n",
       "  'separate_AB_models': True,\n",
       "  'aucs': {'A': array([0.91925466, 0.55980861, 0.81777778]),\n",
       "   'B': array([0.62111801, 0.66985646, 0.72248804])}},\n",
       " {'clf_type': 'AdaBoostClassifier',\n",
       "  'reduction_method': 'Ave_over_samples_ch24_ch8',\n",
       "  'bootstrapped_training_data': None,\n",
       "  'n_rounds_test_train_split': 3,\n",
       "  'separate_AB_models': False,\n",
       "  'aucs': {'A': array([0.69318182, 0.81333333, 0.91304348]),\n",
       "   'B': array([0.84722222, 0.80357143, 0.66435185])}},\n",
       " {'clf_type': 'AdaBoostClassifier',\n",
       "  'reduction_method': 'Ave_over_samples_ch24_ch8',\n",
       "  'bootstrapped_training_data': None,\n",
       "  'n_rounds_test_train_split': None,\n",
       "  'separate_AB_models': True,\n",
       "  'aucs': {'A': array([0.83710407]), 'B': array([0.70496894])}},\n",
       " {'clf_type': 'AdaBoostClassifier',\n",
       "  'reduction_method': 'Ave_over_samples_ch24_ch8',\n",
       "  'bootstrapped_training_data': None,\n",
       "  'n_rounds_test_train_split': None,\n",
       "  'separate_AB_models': False,\n",
       "  'aucs': {'A': array([0.77678571]), 'B': array([0.505])}}]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rf = fitted_models[0]\n",
    "new_rf['reduction_method'] = 'Ave_over_samples_ch24_ch8'\n",
    "new_ada = fitted_models[3]\n",
    "new_ada['reduction_method'] = 'Ave_over_samples_ch24_ch8'\n",
    "new_models = [new_rf, new_ada]\n",
    "\n",
    "%time reduced_ds_test_results = run_model_tests(data_matrix, data_labels, new_models, 1, 500,30,3)\n",
    "\n",
    "with open('../Data/CH24_minus_CH8_test_results.p','wb') as results_file:\n",
    "        pickle.dump(reduced_ds_test_results, results_file)\n",
    "        \n",
    "reduced_ds_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "comic-audience",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5625"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matrix\n",
    "f= lambda X: (X[23,:] - X[7,:]).T\n",
    "\n",
    "X = f(data_matrix).T\n",
    "\n",
    "\n",
    "\n",
    "XA = X[:100]\n",
    "XB = X[100:]\n",
    "yA = data_labels[:100]\n",
    "yB = data_labels[100:]\n",
    "\n",
    "mod = RandomForestClassifier()\n",
    "XA_train, XA_test, yA_train, yA_test = train_test_split(XA, yA)\n",
    "mod.fit(XA_train,yA_train)\n",
    "y_pred = mod.predict_proba(XA_test)[:,1]\n",
    "roc_auc_score(yA_test, y_pred)\n",
    "#print(y_pred)\n",
    "#data_matrix\\\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
